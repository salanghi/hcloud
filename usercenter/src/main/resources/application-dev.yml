server:
  port: 8083
spring:
  application:
    name: usercenter
  cloud:
    nacos:
      discovery:
        server-addr: 127.0.0.1:8848
  sleuth:
    sampler:
      # 采样率的概率，100%采样
      probability: 1.0
      # 每秒采样数字最高为1000
      rate: 1000
  zipkin:
    sender:
      type: kafka
  redis:
    host: 127.0.0.1
    port: 6379
    password:
    timeout: 60000
    database: 0
#  datasource:
#    driver-class-name: com.mysql.jdbc.Driver
#    url: jdbc:mysql://localhost:3306/sharding?useUnicode=true&characterEncoding=utf-8&serverTimezone=UTC
#    username: root
#    password: 135246
  shardingsphere:
    props:
      sql.show: true #是否输出sql
    datasource:
      names: ds0 #指定数据源 名称可以自定义，注意：名称要跟后面的配置一致
      ds0: #配置数据源的连接信息
        type: com.alibaba.druid.pool.DruidDataSource
        driver-class-name: com.mysql.jdbc.Driver
        url: jdbc:mysql://localhost:3306/sharding?useUnicode=true&characterEncoding=utf-8&serverTimezone=Asia/Shanghai&useSSL=false&allowPublicKeyRetrieval=true
        username: root
        password: 135246
    sharding:
      tables:
        t_order:
          actual-data-nodes: ds0.t_order_$->{1..2}
          key-generator:
            column: order_id
            type: SNOWFLAKE
          table-strategy:
            inline:
              algorithm-expression: t_order_$->{order_id%2+1}
              sharding-column: order_id
  kafka:
    bootstrap-servers: 127.0.0.1:9092
    producer:
      batch-size: 16384 #批次大小，默认16k
      acks: all #ACK应答级别，指定分区中必须要有多少个副本收到消息之后才会认为消息成功写入，默认为1只要分区的leader副本成功写入消息；0表示不需要等待任何服务端响应；-1或all需要等待ISR中所有副本都成功写入消息
      retries: 3 #重试次数
      value-serializer: org.apache.kafka.common.serialization.StringSerializer #序列化
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      buffer-memory: 33554432 #缓冲区大小，默认32M
      client-id: abcdefg #客户端ID
      compression-type: none #消息压缩方式，默认为none，另外有gzip、snappy、lz4
      properties:
        retry.backoff.ms: 100 #重试时间间隔，默认100
        linger.ms: 0 #默认为0，表示批量发送消息之前等待更多消息加入batch的时间
        max.request.size: 1048576 #默认1MB，表示发送消息最大值
        connections.max.idle.ms: 540000 #默认9分钟，表示多久后关闭限制的连接
        receive.buffer.bytes: 32768 #默认32KB，表示socket接收消息缓冲区的大小，为-1时使用操作系统默认值
        send.buffer.bytes: 131072 #默认128KB，表示socket发送消息缓冲区大小，为-1时使用操作系统默认值
        request.timeout.ms: 30000 #默认30000ms，表示等待请求响应的最长时间
    consumer:
      bootstrapServers:  127.0.0.1:9092
      topics: testTopic1,testTopic2
      groupId: test
      #后台的心跳线程必须在30秒之内提交心跳,否则会reBalance
      sessionTimeOut: 30000
      #取消自动提交,即便如此 spring会帮助我们自动提交
      enableAutoCommit: false
      #自动提交间隔
      autoCommitInterval: 1000
      maxPollRecords: 50
      #300秒的提交间隔,如果程序大于300秒提交,会报错
      maxPollInterval: 300000
      #心跳间隔
      keyDeserializer: org.apache.kafka.common.serialization.StringDeserializer
      valueDeserializer: org.apache.kafka.common.serialization.StringDeserializer
      autoOffsetReset: latest
      heartbeatInterval: 10000

logging:
  level:
    org.springframework.cloud.sleuth: debug

feign:
  client:
    config:
      feignName:
        ConnectTimeout: 1000
        ReadTimeout: 1000
        NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule

mybatis:
  type-aliases-package: com.helx.usercenter.model
  mapper-locations: classpath:/mapper/*.xml
